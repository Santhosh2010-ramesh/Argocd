version: 0.2

env:
  variables:
    ACCOUNT_ID: 557690580165
    
    # ECR Region - where your Docker image is stored
    ECR_REGION: us-east-1 # Your ECR repository is in us-east-1
    REPO_NAME: expense
    IMAGE_TAG: latest
    IMAGE_URI: 557690580165.dkr.ecr.us-east-1.amazonaws.com/expense:latest # ECR URI uses ECR_REGION

    # EKS Cluster Region - where your EKS cluster is located
    EKS_CLUSTER_REGION: us-west-1 # Your EKS cluster is in us-west-1
    EKS_CLUSTER_NAME: expense-tracker-eks-cluster
    CODEPIPELINE_ROLE_ARN: arn:aws:iam::557690580165:role/service-role/AWSCodePipelineServiceRole-us-west-1-springpipeline # This role accesses EKS in us-west-1

phases:
  install:
    runtime-versions:
      java: corretto17
    commands:
      - echo "Installing dependencies (Maven, Docker, kubectl, jq)..."
      - yum update -y
      - yum install -y maven docker

      # Install kubectl
      - curl -LO "https://dl.k8s.io/release/$(curl -L -s https://dl.k8s.io/release/stable.txt)/bin/linux/amd64/kubectl"
      - chmod +x ./kubectl
      - mv ./kubectl /usr/local/bin/kubectl # Move to a directory in PATH

      # Install jq (for JSON processing, used for aws-auth ConfigMap)
      - yum install -y jq

  pre_build:
    commands:
      - echo "Logging in to Amazon ECR in ${ECR_REGION}..."
      - aws ecr get-login-password --region ${ECR_REGION} | docker login --username AWS --password-stdin ${ACCOUNT_ID}.dkr.ecr.${ECR_REGION}.amazonaws.com

  build:
    commands:
      - echo "Building JAR inside app-tier..."
      - mvn clean package -DskipTests
      - echo "Building Docker image..."
      - docker build -t $REPO_NAME:$IMAGE_TAG .
      - docker tag $REPO_NAME:$IMAGE_TAG $IMAGE_URI

  post_build:
    commands:
      - echo "Pushing image to Amazon ECR in ${ECR_REGION}..."
      - docker push $IMAGE_URI
      - echo "Preparing Kubernetes manifests..."
      - echo "Listing files in current directory:"
      - ls -la
      - pwd
      - mkdir -p k8s-out
      - pwd
      - sed "s|IMAGE_PLACEHOLDER|$IMAGE_URI|g" deployment.yaml > k8s-out/deployment.yaml
      - pwd
      - cp service.yaml k8s-out/service.yaml
      - echo "Done preparing artifacts."

      # EKS Deployment Steps
      - echo "Configuring kubectl for EKS cluster: ${EKS_CLUSTER_NAME} in region: ${EKS_CLUSTER_REGION}..."
      - aws eks update-kubeconfig --name ${EKS_CLUSTER_NAME} --region ${EKS_CLUSTER_REGION}

      - echo "Granting cluster-admin permissions to CodePipeline role via aws-auth ConfigMap..."
      - |
        # Fetch the current aws-auth ConfigMap
        kubectl get configmap aws-auth -n kube-system -o json > /tmp/aws-auth-configmap.json
        
        # Add or update the CodePipeline role in mapRoles, ensuring correct JSON structure
        jq --arg rolearn "${CODEPIPELINE_ROLE_ARN}" \
           '.data.mapRoles |= (fromjson | [.[] | select(.rolearn != $rolearn)] + [{"rolearn":$rolearn,"username":"code-pipeline-admin","groups":["system:masters"]}] | tojson)' \
           /tmp/aws-auth-configmap.json > /tmp/aws-auth-patch.json
        
        # Apply the patched ConfigMap
        kubectl patch configmap aws-auth -n kube-system --patch-file /tmp/aws-auth-patch.json
        echo "aws-auth ConfigMap updated successfully."

      - echo "Deploying Kubernetes manifests to EKS cluster..."
      - kubectl apply -f k8s-out/deployment.yaml
      - kubectl apply -f k8s-out/service.yaml
      - echo "Kubernetes deployment and service applied."

artifacts:
  base-directory: k8s-out
  files:
    - deployment.yaml
    - service.yaml
